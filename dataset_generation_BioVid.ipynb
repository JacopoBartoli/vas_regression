{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset_generation_BioVid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacopoBartoli/vas_regression/blob/main/dataset_generation_BioVid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-kblIM6FlLu"
      },
      "source": [
        "# 1) Organize imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG0t8yE7Fx6y"
      },
      "source": [
        "In this section we install and import the needed packages. Then we mount our GDrive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6zDrfY1Ft7D"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG7eghoXGLTL"
      },
      "source": [
        "Useful paths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6EYvyL7hMMV"
      },
      "source": [
        "# Name of file with data for create dataset\n",
        "file_name = 'dataset_final_1000.csv'\n",
        "\n",
        "# Path of two part of dataset\n",
        "COORD_DF_PATH = '/content/gdrive/My Drive/IVA/Dataset_2/' + file_name\n",
        "SEQ_DF_PATH = '/content/gdrive/My Drive/IVA/Dataset_2/labels1.csv'\n",
        "\n",
        "# Path where save the data extract from dataset\n",
        "DATASET_DIR = '/content/gdrive/My Drive/IVA/Dataset_2/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ds2WVcXG-r7"
      },
      "source": [
        "Mount the drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iVdUcC2WwC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054c6fb3-eff0-4f7f-b3a5-54dcde7d29aa"
      },
      "source": [
        "# Mount your drive to access the dataset.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOZcdU-vKTXf"
      },
      "source": [
        "# 2) BioVid Heat Pain Dataset Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-IAmjxax_Dx"
      },
      "source": [
        "In this section we extract the data from dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnq3JrGt61U7"
      },
      "source": [
        "## 2.1) Set parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_ZHwYYz67R9"
      },
      "source": [
        "# List of index of landmarks to be taken into consideration\n",
        "\n",
        "selected_lndks_idx = range(0,70)\n",
        "\n",
        "num_lndks = len(selected_lndks_idx)\n",
        "\n",
        "# Index of central landmark of the frame\n",
        "\n",
        "central_lndk = 30\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR2IJh5ZyDuU"
      },
      "source": [
        "##2.2) Utility functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgmDAGc7yJyC"
      },
      "source": [
        "Define some utilities functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0kxGKOeOdIb"
      },
      "source": [
        "# Get the velocities of all selected landmark for each frame of each sequence\n",
        "\n",
        "def get_velocities_frames():\n",
        "    coord_df = pd.read_csv(COORD_DF_PATH)\n",
        "    seq_df = pd.read_csv(SEQ_DF_PATH)\n",
        "    velocities = []\n",
        "\n",
        "    list_seq = coord_df['0'].unique()\n",
        "\n",
        "    for seq_num in list_seq:\n",
        "\n",
        "        vel_seq = []\n",
        "\n",
        "        lndks = coord_df.loc[coord_df['0'] == seq_num].values\n",
        "\n",
        "        lndks = lndks[:, 2:]\n",
        "\n",
        "        # Start frame\n",
        "\n",
        "        frame = lndks[0]\n",
        "\n",
        "        frame_nose_x = frame[central_lndk]\n",
        "        frame_nose_y = frame[central_lndk + num_lndks]\n",
        "\n",
        "\n",
        "        frame_nose = []\n",
        "\n",
        "        for i in range(num_lndks):\n",
        "            frame_nose.append(frame_nose_x)\n",
        "        for i in range(num_lndks):\n",
        "            frame_nose.append(frame_nose_y)\n",
        "\n",
        "        frame_centered_prec = frame - frame_nose\n",
        "\n",
        "        for id_frame in range(1,len(lndks)):\n",
        "\n",
        "            frame = lndks[id_frame]\n",
        "\n",
        "            frame_centered_succ = frame - frame_nose\n",
        "\n",
        "            frame_centered_succ_array = np.array(frame_centered_succ)\n",
        "            frame_centered_prec_array = np.array(frame_centered_prec)\n",
        "\n",
        "            # Velocity of landmarks\n",
        "\n",
        "            lndk_vel = np.power(np.power(frame_centered_succ_array[0:num_lndks]-frame_centered_prec_array[0:num_lndks], 2) +\n",
        "                               np.power(frame_centered_succ_array[num_lndks:]-frame_centered_prec_array[num_lndks:], 2), 0.5)\n",
        "\n",
        "            vel_seq.append(np.array(lndk_vel))\n",
        "\n",
        "\n",
        "            frame_nose_x = frame[central_lndk]\n",
        "            frame_nose_y = frame[central_lndk + num_lndks]\n",
        "\n",
        "            frame_nose = []\n",
        "\n",
        "            for i in range(num_lndks):\n",
        "                frame_nose.append(frame_nose_x)\n",
        "            for i in range(num_lndks):\n",
        "                frame_nose.append(frame_nose_y)\n",
        "\n",
        "            frame_centered_prec = frame - frame_nose\n",
        "\n",
        "        velocities.append(vel_seq)\n",
        "\n",
        "\n",
        "    return velocities\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11ND5LtH8BgE"
      },
      "source": [
        "## 2.3) Select train or test dataset generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65ykkMZu8JDE"
      },
      "source": [
        "# Train\n",
        "\n",
        "name_csv = DATASET_DIR + 'all-train-velocity-' + str(len(selected_lndks_idx)) + '-' + file_name\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmp94mms8gKu"
      },
      "source": [
        "# Test\n",
        "\n",
        "name_csv = DATASET_DIR + 'all-test-velocity-' + str(len(selected_lndks_idx)) + '-' + file_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7Oa7UGx759_"
      },
      "source": [
        "# Create a csv file, for the training or test dataset\n",
        "\n",
        "velocities = get_velocities_frames()\n",
        "seq_df = pd.read_csv(SEQ_DF_PATH)\n",
        "\n",
        "\n",
        "frame = []\n",
        "lst = []\n",
        "element = []\n",
        "sequenza = []\n",
        "for id_seq in range(0, len(velocities)):\n",
        "    vas = seq_df.iloc[id_seq][1]\n",
        "    element.append(id_seq)\n",
        "    sequenza = velocities[id_seq]\n",
        "    for id_frames in range(0, len(sequenza)):\n",
        "        element.append(id_frames)\n",
        "        frame = sequenza[id_frames]\n",
        "        for v in range(0, len(frame)):\n",
        "            velocita = frame[v]\n",
        "            element.append(velocita)\n",
        "        element.append(vas)\n",
        "        lst.append(element)\n",
        "        element = [id_seq]\n",
        "    element = []\n",
        "\n",
        "\n",
        "\n",
        "col = ['Sequenza','Frame']\n",
        "for i in range(0, len(selected_lndks_idx)):\n",
        "    s = 'Vel' + str(i)\n",
        "    col.append(s)\n",
        "col.append('Label')\n",
        "\n",
        "df = pd.DataFrame(lst,columns=col)\n",
        "print(df)\n",
        "\n",
        "df.to_csv(name_csv, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}