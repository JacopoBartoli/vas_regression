{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dataset_generation.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNXD4AHmDAu2sXG4n2tx+Rx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MBytdDNvfO7x"},"source":["Mount the drive"]},{"cell_type":"code","metadata":{"id":"3iVdUcC2WwC4"},"source":["# Mount your drive to access the dataset.\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ls -l \"/content/gdrive/My Drive/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4dISPDQLgHYu"},"source":["Save some useful paths"]},{"cell_type":"code","metadata":{"id":"R6EYvyL7hMMV"},"source":["coord_df_path = '/content/gdrive/My Drive/IVA/Datasets/info/2d_skeletal_data_unbc_coords.csv'\n","seq_df_path = '/content/gdrive/My Drive/IVA/Datasets/info/2d_skeletal_data_unbc_sequence.csv'\n","fig_dir = '/content/gdrive/My Drive/IVA/Datasets/info/histogram.png'\n","dataset_dir = '/content/gdrive/My Drive/IVA/Datasets/info/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tLc0XPJkaIZl"},"source":["# 1) Information on dataset distribution"]},{"cell_type":"code","metadata":{"id":"BB2CoRMMWIyV"},"source":["import pandas as pd\n","import statistics\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bn_hD43xhR02"},"source":["Prints the average, maximum and minimum length of the sequences and saves a histogram with all the lengths of the sequences"]},{"cell_type":"code","metadata":{"id":"GO4kePhWWamk"},"source":["data = pd.read_csv(seq_df_path)\n","\n","print(data)\n","\n","print(\"Info su lunghezza sequenze del dataset:\")\n","print(\"Medium length : \" , data[\"num_frames\"].mean())\n","print(\"Max length : \" ,data[\"num_frames\"].max())\n","print(\"Min length : \" ,data[\"num_frames\"].min())\n","\n","data['num_frames'].plot(kind='hist',bins=200)\n","plt.axvline(dati['num_frames'].mean(), c='red')\n","plt.xlabel('Number of Frame')\n","plt.ylabel('Grequencies')\n","plt.title(\"sequence length distribution\")\n","plt.savefig(fig_dir, dpi=200)\n","plt.close()\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CLnqvBFgFUPB"},"source":["# 2) Dataset Generation\n"]},{"cell_type":"code","metadata":{"id":"keNLoO8MFeS4"},"source":["import pickle\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import operator\n","from sklearn.preprocessing import RobustScaler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AKTmx4_UKvq4"},"source":["Select only the indexes of the landmarks to be used\n"]},{"cell_type":"code","metadata":{"id":"s2c3_oJgI0SW"},"source":["selected_lndks_idx = range(0, 66)\n","#selected_lndks_idx = [5, 11, 19, 24, 30, 37, 41, 44, 46, 50, 52, 56, 58]\n","\n","train_video_idx = range(0,179)\n","test_video_idx = range(180,200)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5iuv3YetjTHF"},"source":["##2.1) Utility functions\n","Define some utilities functions"]},{"cell_type":"code","metadata":{"id":"X8Eh19CXFXwz"},"source":["# Get the velocities of all selected landmark for each frame of each sequence\n","\n","def get_velocities_frames():\n","  \n","  coord_df = pd.read_csv(coord_df_path)\n","  seq_df = pd.read_csv(seq_df_path)\n","  velocities = []\n","  for seq_num in np.arange(seq_df.shape[0]):\n","      lndks = coord_df.loc[coord_df['0'] == seq_num].values\n","      lndks = lndks[:, 2:]\n","      num_lndks = 66\n","      num_frames = seq_df['num_frames'][seq_num]\n","      centroid_x = np.array([np.sum(lndks[i, 0:num_lndks]) / num_lndks for i in range(num_frames)])\n","      centroid_y = np.array([np.sum(lndks[i, num_lndks:]) / num_lndks for i in range(num_frames)])\n","\n","      offset = np.hstack((np.repeat(centroid_x.reshape(-1, 1), num_lndks, axis=1),\n","                          np.repeat(centroid_y.reshape(-1, 1), num_lndks, axis=1)))\n","\n","      lndks_centered = lndks - offset\n","      lndks_centered[:, 30] = centroid_x\n","\n","      lndks_centered[:, 30 + num_lndks] = centroid_y\n","      lndk_vel = np.power(np.power(lndks_centered[0:lndks_centered.shape[0] - 1, 0:num_lndks] -\n","                                  lndks_centered[1:lndks_centered.shape[0], 0:num_lndks], 2) +\n","                          np.power(lndks_centered[0:lndks_centered.shape[0] - 1, num_lndks:] -\n","                                  lndks_centered[1:lndks_centered.shape[0], num_lndks:], 2), 0.5)\n","      data_velocities = []\n","      for k in np.arange(1, lndk_vel.shape[0]):\n","          data_velocities.append(np.array(lndk_vel[k, selected_lndks_idx]))\n","      velocities.append(np.array(data_velocities))\n","  return velocities"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NGqOaDN5NPaf"},"source":["##2.2) Dataset Generation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ISew7wfGf7x","executionInfo":{"status":"ok","timestamp":1633516078388,"user_tz":-120,"elapsed":11276,"user":{"displayName":"ANTONIO ACUNZO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16391969483919847623"}},"outputId":"a236c7dc-314a-4763-9997-8cd48f02a3f0"},"source":["# Create two csv files, one for the training dataset and one for the test dataset\n","\n","velocities = get_velocities_frames()\n","seq_df = pd.read_csv(seq_df_path)\n","\n","list = []\n","element = []\n","sequenza = []\n","for id_seq in range(0, len(velocities)):\n","    vas = seq_df.iloc[id_seq][1]\n","    element.append(id_seq)\n","    sequenza = velocities[id_seq]\n","    for id_frames in range(0, len(sequenza)):\n","        element.append(id_frames)\n","        frame = sequenza[id_frames]\n","        for v in range(0, len(frame)):\n","            velocita = frame[v]\n","            element.append(velocita)\n","        element.append(vas)\n","        list.append(element)\n","        element = [id_seq]\n","    element = []\n","\n","col = ['Sequenza','Frame']\n","for i in range(0, len(selected_lndks_idx)):\n","    s = 'Vel' + str(i)\n","    col.append(s)\n","col.append('Label')\n","\n","df = pd.DataFrame(list,columns=col)\n","\n","print(df)\n","\n","train = df.loc[(df['Sequenza'] < 180)]\n","test = df.loc[(df['Sequenza'] >= 180)]\n","\n","name_csv_train = dataset_dir + 'train-velocity-' + str(len(selected_lndks_idx)) + '.csv'\n","name_csv_test = dataset_dir + 'test-velocity-' + str(len(selected_lndks_idx)) + '.csv'\n","\n","train.to_csv(name_csv_train, index=False)\n","test.to_csv(name_csv_test, index=False)\n","\n","\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["       Sequenza  Frame      Vel0      Vel1  ...     Vel63     Vel64     Vel65  Label\n","0             0      0  0.070404  0.156512  ...  0.130682  0.264413  0.229226      0\n","1             0      1  0.125513  0.114344  ...  0.120285  0.138199  0.126977      0\n","2             0      2  0.253132  0.231857  ...  0.081278  0.111015  0.104563      0\n","3             0      3  0.187514  0.174368  ...  0.061480  0.069704  0.061332      0\n","4             0      4  0.229464  0.197635  ...  0.051159  0.047535  0.046308      0\n","...         ...    ...       ...       ...  ...       ...       ...       ...    ...\n","47993       199    128  0.278181  0.243939  ...  0.062450  0.090637  0.052599      0\n","47994       199    129  0.235192  0.215203  ...  0.007179  0.060353  0.065273      0\n","47995       199    130  0.214192  0.216479  ...  0.035070  0.074119  0.118038      0\n","47996       199    131  0.201538  0.189191  ...  0.035153  0.043057  0.090181      0\n","47997       199    132  0.337752  0.305015  ...  0.064156  0.112064  0.058628      0\n","\n","[47998 rows x 69 columns]\n"]}]}]}