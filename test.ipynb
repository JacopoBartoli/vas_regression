{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3mr9qPI0vSKU",
        "9P7SvR97OnqG",
        "150Z-yzAOnqP",
        "VZRcUIsDOnqR",
        "YMlSIkZdTM17",
        "9VvZMY3A1k3B",
        "ckT5WkCUpnEA",
        "FsWHKn-ivw5v",
        "k3pxHFQVFwdd",
        "yvhdmvOAyjZ3",
        "oLeUdXBQToDq",
        "ud5JnnWNGUk6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacopoBartoli/vas_regression/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mr9qPI0vSKU"
      },
      "source": [
        "#1) Install packages and organize imports.\n",
        "In this section we install the needed packages and import them.\n",
        "We set some variables for the used paths, and mount GDrive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRCPE_6yYdDg"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrMRVkjJE88R"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorboard\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import time, datetime, math, io, sklearn.preprocessing, itertools\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEl4lSFBK40Y"
      },
      "source": [
        "Useful paths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xugDyHkCZlbm"
      },
      "source": [
        "# Path to the datasets.\n",
        "DATASET_DIR = '/content/gdrive/My Drive/IVA/data/'\n",
        "# Path to where we save logs.\n",
        "LOGS_DIR = '/content/gdrive/My Drive/IVA/logs'\n",
        "# Path to where we save the checkpoints.\n",
        "CHECKPOINT_DIR = '/content/gdrive/My Drive/IVA/checkpoint/train'\n",
        "# Path to where we save the model.\n",
        "MODEL_DIR = '/content/gdrive/My Drive/IVA/model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_tfWIAAxaPB"
      },
      "source": [
        "Mount the drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUIi6rICZcI8"
      },
      "source": [
        "# Mount your drive to access the dataset.\n",
        "# Remember to link the dataset as explained above.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P7SvR97OnqG"
      },
      "source": [
        "#2) Manage the data.\n",
        "In this section we manipulate and extract the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "150Z-yzAOnqP"
      },
      "source": [
        "##2.1) Load the train set.\n",
        "\n",
        "Define the name of the dataset used for \n",
        "training.\n",
        "\n",
        "The data in the .csv can have a variable number of features. But three column are always needed. They are 'Sequenza', 'Frame' and 'Label'.\n",
        "The first represent the id of a sequence, the second the id of a frame. The third represent the label of each frame.\n",
        "\n",
        "\n",
        "Each row of the file need to represent a frame, and each frame of the same sequence need to have the same label.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eXCz-uXOnqQ"
      },
      "source": [
        "# Name of the dataset used.\n",
        "TEST_SET = 'test-velocity-66-sampled.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaTqWROxJ2D1"
      },
      "source": [
        "Load the train set from a .csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW3SLDKN-NBi"
      },
      "source": [
        "df = pd.read_csv(DATASET_DIR + TEST_SET)\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZRcUIsDOnqR"
      },
      "source": [
        "## 2.2) Divide the labels from the data.\n",
        "\n",
        "The labels and the data are saved in different data structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC-wuiZBobvZ"
      },
      "source": [
        "# Needed later for confusion matrix\n",
        "number_of_labels = df['Label'].tolist()\n",
        "number_of_labels = len(list(dict.fromkeys(number_of_labels))) - 1\n",
        "\n",
        "df_test = df.drop(['Frame'], axis=1)\n",
        "\n",
        "# Extract the labels.\n",
        "lbl_test = df_test['Label']\n",
        "\n",
        "# Remove the labels from the data.\n",
        "df_test = df_test.drop(['Label'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnUzxRESX5qi"
      },
      "source": [
        "print(df_test.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMlSIkZdTM17"
      },
      "source": [
        "##2.3) Preprocessing of the sequences.\n",
        "\n",
        "In the dataset each row represent a frame of the sequence. Each frame in a sequence has the same label. We want to make some preprocessing for having a dataset that has a single label for each sequence (not one for each frame). We want that each item of the dataset represent a whole sequence and not a frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp4TI_UTwStp"
      },
      "source": [
        "# Need to pass different in a separate ways lbl and data.\n",
        "def preprocessing_sequences(data, lbl):\n",
        "  # Preprocess the labels.\n",
        "  # The label and the ids of the sequence are concatenated together.\n",
        "  seq_ids = data['Sequenza']\n",
        "\n",
        "  tmp = pd.concat([seq_ids, lbl], axis=1)\n",
        "  tmp = tmp.set_index('Sequenza')\n",
        "  # Then they are gourped by sequence id so we can have a single label for each\n",
        "  # sequence.\n",
        "  tmp = tmp.groupby(level='Sequenza').mean()\n",
        "\n",
        "  labels = tmp['Label'].values\n",
        "\n",
        "  min_seq = data['Sequenza'].min()\n",
        "  num_seqs = data['Sequenza'].max() - data['Sequenza'].min() + 1\n",
        "  min_seq = int(min_seq)\n",
        "  num_seqs = int(num_seqs)\n",
        "\n",
        "  # Create the new dataset.\n",
        "  temp = []\n",
        "  for id in tqdm(range(min_seq, min_seq + num_seqs)):\n",
        "    # Extract sequences one by one.\n",
        "    seq = data.loc[data['Sequenza'] == id]\n",
        "\n",
        "    # Remove the unused columns.\n",
        "    seq = seq.drop(['Sequenza'], axis=1)\n",
        "    num_col = len(seq.columns)\n",
        "\n",
        "    # Iterate over each row of the selected sequence  \n",
        "    temp_row = []\n",
        "    for index, row in seq.iterrows():\n",
        "      temp_row = np.append(temp_row, row)\n",
        "    temp_row = np.reshape(temp_row, (-1, num_col))\n",
        "\n",
        "    temp.append(temp_row[:])\n",
        "\n",
        "  return temp, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J8MI_pQGT4j"
      },
      "source": [
        "df_test, lbl_test = preprocessing_sequences(df_test, lbl_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VvZMY3A1k3B"
      },
      "source": [
        "## 2.4) Create and manage the test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLPf4DQ6OnqT"
      },
      "source": [
        "ds_test = tf.data.Dataset.from_tensor_slices((df_test, lbl_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzAf41xJu1PL"
      },
      "source": [
        "BATCH_SIZE = 1\n",
        "BUFFER_SIZE = 5000\n",
        "random_seed = 1337"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmmKbrPZYibk"
      },
      "source": [
        "Function to apply some preprocessing when making batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bh-ogBsyccq"
      },
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .cache()\n",
        "      .shuffle(BUFFER_SIZE,seed=random_seed)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(tf.data.AUTOTUNE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yug1V-wIpTqm"
      },
      "source": [
        "Now we divide in batches the validation and training sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYlfnP6jyfoR"
      },
      "source": [
        "test_batches = make_batches(ds_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckT5WkCUpnEA"
      },
      "source": [
        "# 3) Evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsWHKn-ivw5v"
      },
      "source": [
        "## 3.1) Set the the error metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRVZLF5ETubo"
      },
      "source": [
        "# This loss and accuracy objects are meant for regression.\n",
        "# For classifications other metrics will be needed.\n",
        "error_object = tf.keras.metrics.MeanAbsoluteError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3pxHFQVFwdd"
      },
      "source": [
        "## 3.2) Custom implementation of the error function. \n",
        "Add a way to customize the error function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YInErpodyKFT"
      },
      "source": [
        "def error_function(real, pred):\n",
        "\n",
        "  errors = error_object(real, pred)\n",
        "  \n",
        "  return errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTr2DpFCY9Ft"
      },
      "source": [
        "Create the metrics object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anzv8mRpISiF"
      },
      "source": [
        "test_error = tf.keras.metrics.Mean(name='test_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvhdmvOAyjZ3"
      },
      "source": [
        "## 3.3) Set the paths for Tensorboard.\n",
        "The test_log_dir need to be associate to a valid train_log_dir using their timestamp."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk3_uzV8Y06P"
      },
      "source": [
        "# In this case we use the model associated to the train of the 2021-10-14 at 8:34:14\n",
        "current_time = datetime.datetime(2021, 10, 14, 8, 34, 12).strftime(\"%Y%m%d-%H%M%S\")\n",
        "test_log_dir = LOGS_DIR + '/gradient_tape/' + current_time + '/test'\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8GMuCd5tu_Q"
      },
      "source": [
        "### 3.3.1) Define some utilities functions for confusion matrix visualization inside Tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoBIFl17yJLn"
      },
      "source": [
        "# Needed for confusion matrix visualization\n",
        "# This can be done just because the regression task has a finite number of labels.\n",
        "tag_list = [float(_dummy) for _dummy in range(number_of_labels + 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZitdKXNAyf6_"
      },
      "source": [
        "Utilities functions for confusion matrix visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IqyEQnytuBc"
      },
      "source": [
        "def plot_to_image(figure):\n",
        "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "  # Save the plot to a PNG in memory.\n",
        "  buf = io.BytesIO()\n",
        "  plt.savefig(buf, format='png')\n",
        "  # Closing the figure prevents it from being displayed directly inside\n",
        "  # the notebook.\n",
        "  plt.close(figure)\n",
        "  buf.seek(0)\n",
        "  # Convert PNG buffer to TF image\n",
        "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "  # Add the batch dimension\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  return image\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names):\n",
        "  \"\"\"\n",
        "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "\n",
        "  Args:\n",
        "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "    class_names (array, shape = [n]): String names of the integer classes\n",
        "  \"\"\"\n",
        "  figure = plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(class_names))\n",
        "  plt.xticks(tick_marks, class_names, rotation=45)\n",
        "  plt.yticks(tick_marks, class_names)\n",
        "\n",
        "  # Compute the labels from the normalized confusion matrix.\n",
        "  # Remove number equals to zero.\n",
        "  divider = cm.sum(axis=1)[:, np.newaxis]\n",
        "  divider = np.where(divider!=0, divider, 1)\n",
        "\n",
        "  labels = np.around(cm.astype('float') / divider, decimals=2)\n",
        "\n",
        "  # Use white text if squares are dark; otherwise black.\n",
        "  threshold = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "    plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  return figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLeUdXBQToDq"
      },
      "source": [
        "## 3.4) Load the model.\n",
        "Since it's a custom model it can't be load as .h5 config."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcGjJXlI68jH"
      },
      "source": [
        "!ls -l '/content/gdrive/My Drive/IVA/model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfzEYlhr2nDz"
      },
      "source": [
        "transformer = keras.models.load_model('/content/gdrive/My Drive/IVA/model/' + current_time + '/transformers')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud5JnnWNGUk6"
      },
      "source": [
        "## 3.5) Evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R144HVdyxcVh"
      },
      "source": [
        "def test_step(inp,tar):\n",
        "  tar_real = tar\n",
        "\n",
        "  \n",
        "  predictions = transformer(inp, training = False)\n",
        "  error = error_function(tar_real, predictions)\n",
        "\n",
        "\n",
        "  test_error(error)\n",
        "  \n",
        "  return predictions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3c-T4EY0NQ9"
      },
      "source": [
        "start = time.time()\n",
        "  \n",
        "test_error.reset_states()\n",
        "\n",
        "# Needed for histogram visualization.\n",
        "predictions_histogram = []\n",
        "labels_histogram = []\n",
        "y_pred, y_true = [], [] # Needed for the confusion matrix\n",
        "\n",
        "\n",
        "for (batch, (inp, tar)) in enumerate(test_batches):\n",
        "    predictions = test_step(inp, tar)\n",
        "\n",
        "    # Save the histogram of predictions.\n",
        "    predictions_histogram = np.hstack((predictions_histogram, tf.reshape(predictions, len(predictions))))    \n",
        "    labels_histogram = np.hstack((labels_histogram, tar))\n",
        "\n",
        "    # Transform back the label value, from the 0 to 1 representation,\n",
        "    # It's a simple scale back.\n",
        "    y_pred.extend(np.around(np.array(predictions)*number_of_labels))\n",
        "    y_true.extend(np.around(np.array(tar)*number_of_labels))\n",
        "\n",
        "\n",
        "\n",
        "# Build confusion matrix.\n",
        "cm = confusion_matrix(y_pred, y_true)\n",
        "figure = plot_confusion_matrix(cm, class_names=tag_list)\n",
        "cm_image = plot_to_image(figure)\n",
        "\n",
        "with test_summary_writer.as_default():\n",
        "   tf.summary.scalar('Error', test_error.result(),step = 0)\n",
        "   tf.summary.histogram('Predictions distribution', predictions_histogram, step=0)\n",
        "   tf.summary.histogram('Ground Truth distribution', labels_histogram, step=0)\n",
        "   tf.summary.image('Confusion Matrix', cm_image, step=0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}